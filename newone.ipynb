{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e3290a-2c8e-44b9-a3c7-4f14aa1f8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "from recorder import Recorder\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "# import librosa\n",
    "# from librosa import display\n",
    "# from IPython.display import Audio\n",
    "from scipy.fft import fft, fftfreq\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "218b0049-ac5b-44e8-8250-be149e6b19f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture('ambulance.mp4')\n",
    "#cap = cv2.VideoCapture(1)\n",
    "cap.set(3, frameWidth)\n",
    "cap.set(4, frameHeight)\n",
    "cap.set(10,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ac7214a-9b24-42da-9d78-b7b8316c375d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "np.set_printoptions(suppress=True)\n",
    "model = tensorflow.keras.models.load_model('verynewmod.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02206c6a-4de5-4ccc-ac0a-8c905038b279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def emergency():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bc1374-42e6-46cb-8bf8-6ef11f49b337",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (300,300,3) into shape (224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m img_res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(img)\n\u001b[0;32m     10\u001b[0m normalized_image_array \u001b[38;5;241m=\u001b[39m (img_res\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m127.0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m normalized_image_array\n\u001b[0;32m     12\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#print(prediction[0][0])\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#print(text)\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (300,300,3) into shape (224,224,3)"
     ]
    }
   ],
   "source": [
    "amc = 0\n",
    "fir = 0\n",
    "pol = 0\n",
    "while True:\n",
    "    \n",
    "    success, img = cap.read()\n",
    "    image = img\n",
    "    img = cv2.resize(img,(300,300))\n",
    "    img_res = np.asarray(img)\n",
    "    normalized_image_array = (img_res.astype(np.float32) / 127.0) - 1\n",
    "    data[0] = normalized_image_array\n",
    "    prediction = model.predict(data)\n",
    "    #print(prediction[0][0])\n",
    "    \n",
    "    #print(text)\n",
    "    ambulanc_acc =(prediction[0][0])\n",
    "    firengin_acc = [] \n",
    "    \n",
    "    ambulance = (f'ambulance:{prediction[0][0].round()}')\n",
    "    firengine = (f'firengine:{prediction[0][1].round()}')\n",
    "    policecar = (f'policecar:{prediction[0][2].round()}')\n",
    "    trafic =    (f'trafic:{prediction[0][3].round()}')\n",
    "    \n",
    "    \n",
    "    if ambulance == 'ambulance:1.0':\n",
    "        amc = amc + 1\n",
    "    if amc == 20:\n",
    "        amc = 0\n",
    "        cv2.putText(image,'Ambulance detecated',(450,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        \n",
    "        \n",
    "       \n",
    "    if firengine == 'firengine:1.0':\n",
    "        cv2.putText(image,'Firengine detecated',(450,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "    \n",
    "    if policecar == 'policecar:1.0':\n",
    "        cv2.putText(image,'Policecar detecated',(450,100),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2)\n",
    "        \n",
    "   # if trafic == 'trafic:1.0':\n",
    "       # cv2.putText(image,'trafic detecated',(50,150),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),2)\n",
    "    print(amc)\n",
    "        \n",
    "    text = (f'{ambulance}% {firengine}% {policecar}% {trafic}% {amc}')\n",
    "   # print(text)\n",
    "    \n",
    "    cv2.putText(image,text,(15,20),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),2)\n",
    "    cv2.imshow(\"Result\", image)\n",
    "    if cv2.waitKey(1) and 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80e01ff-c414-497e-b1a0-8b2cda78fd61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
